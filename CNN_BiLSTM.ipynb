{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":24.033319,"end_time":"2025-10-28T14:45:51.487656","environment_variables":{},"exception":true,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-10-28T14:45:27.454337","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"d6fdff9e","cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, Model, regularizers\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\nimport os\nimport cv2\nfrom sklearn.preprocessing import label_binarize\nfrom itertools import cycle\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-10-28T14:45:31.179739Z","iopub.status.busy":"2025-10-28T14:45:31.179447Z","iopub.status.idle":"2025-10-28T14:45:48.043566Z","shell.execute_reply":"2025-10-28T14:45:48.042853Z"},"papermill":{"duration":16.868888,"end_time":"2025-10-28T14:45:48.044927","exception":false,"start_time":"2025-10-28T14:45:31.176039","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2025-10-28 14:45:33.040040: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1761662733.276209      13 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1761662733.342915      13 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"execution_count":1},{"id":"98a38e11","cell_type":"code","source":"# --- Parameters ---\nDATASET_PATH = \"/kaggle/input/augmented-alzheimer-dataset/AugmentedAlzheimerDataset\"\nIMG_HEIGHT = 128\nIMG_WIDTH = 128\nBATCH_SIZE = 32\nNUM_CLASSES = 4 # Mild, VeryMild, Non, Moderate\n\n\n# Create the training dataset (80% of the data)\ntrain_dataset = tf.keras.utils.image_dataset_from_directory(\n    DATASET_PATH,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=123,\n    image_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=BATCH_SIZE,\n    color_mode='grayscale' # Using grayscale as the image appears to be single-channel\n)\n\n# Create the validation dataset (20% of the data)\nvalidation_dataset = tf.keras.utils.image_dataset_from_directory(\n    DATASET_PATH,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=123,\n    image_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=BATCH_SIZE,\n    color_mode='grayscale'\n)\n\n\nclass_names = train_dataset.class_names\nprint(\"Found classes:\", class_names)\n\n\n# Normalize pixel values from [0, 255] to [0, 1]\nnormalization_layer = layers.Rescaling(1./255)\n\ntrain_dataset = train_dataset.map(lambda x, y: (normalization_layer(x), y))\nvalidation_dataset = validation_dataset.map(lambda x, y: (normalization_layer(x), y))\n\n\nAUTOTUNE = tf.data.AUTOTUNE\ntrain_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)\nvalidation_dataset = validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)","metadata":{"execution":{"iopub.execute_input":"2025-10-28T14:45:48.049767Z","iopub.status.busy":"2025-10-28T14:45:48.049347Z","iopub.status.idle":"2025-10-28T14:45:48.357364Z","shell.execute_reply":"2025-10-28T14:45:48.356530Z"},"papermill":{"duration":0.311324,"end_time":"2025-10-28T14:45:48.358418","exception":true,"start_time":"2025-10-28T14:45:48.047094","status":"failed"},"tags":[]},"outputs":[{"ename":"NotFoundError","evalue":"Could not find directory /kaggle/input/augmented-alzheimer-dataset/AugmentedAlzheimerDataset","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_13/2862764677.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# --- Load Data ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Create the training dataset (80% of the data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m train_dataset = tf.keras.utils.image_dataset_from_directory(\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/image_dataset_utils.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, pad_to_aspect_ratio, data_format, verbose)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m     image_paths, labels, class_names = dataset_utils.index_directory(\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/dataset_utils.py\u001b[0m in \u001b[0;36mindex_directory\u001b[0;34m(directory, labels, formats, class_names, shuffle, seed, follow_links, verbose)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"inferred\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0msubdirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mlist_directory_v2\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    766\u001b[0m   \"\"\"\n\u001b[1;32m    767\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m     raise errors.NotFoundError(\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0mnode_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0mop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m: Could not find directory /kaggle/input/augmented-alzheimer-dataset/AugmentedAlzheimerDataset"]}],"execution_count":2},{"id":"4b2de80a","cell_type":"code","source":"# Custom Self-Attention Layer\nclass SelfAttention(layers.Layer):\n    def __init__(self, units):\n        super(SelfAttention, self).__init__()\n        self.W1 = layers.Dense(units, activation='tanh')\n        self.W2 = layers.Dense(1)\n\n    def call(self, inputs):\n        \n        score = self.W2(self.W1(inputs)) # (batch_size, sequence_length, 1)\n        \n       \n        attention_weights = tf.nn.softmax(score, axis=1)\n        \n        \n        context_vector = attention_weights * inputs\n        context_vector = tf.reduce_sum(context_vector, axis=1) # (batch_size, hidden_units)\n        \n        return context_vector\n\n# Model Definition with CNN + BiLSTM\ndef build_cnn_bilstm_attention_model(input_shape, num_classes):\n    inputs = layers.Input(shape=input_shape)\n    \n    \n    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(inputs)\n    x = layers.MaxPooling2D((2, 2))(x)\n    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n    x = layers.MaxPooling2D((2, 2))(x)\n    last_conv = layers.Conv2D(128, (3, 3), padding='same', activation='relu', name='last_conv')(x)\n    \n    \n    reshaped = layers.Reshape((32, 32 * 128))(last_conv)\n    \n    \n    bilstm = layers.Bidirectional(\n        layers.LSTM(units=128, return_sequences=True, kernel_regularizer=regularizers.l2(0.001))\n    )(reshaped)\n    \n  \n    attention_output = SelfAttention(units=128)(bilstm)\n    \n    \n    dropout1 = layers.Dropout(0.5)(attention_output)\n    \n    \n    dense1 = layers.Dense(128, activation='relu')(dropout1)\n    dropout2 = layers.Dropout(0.5)(dense1)\n    outputs = layers.Dense(num_classes, activation='softmax')(dropout2)\n    \n    model = Model(inputs=inputs, outputs=outputs)\n    return model\n\n\ninput_shape = (IMG_HEIGHT, IMG_WIDTH, 1)\nmodel = build_cnn_bilstm_attention_model(input_shape, NUM_CLASSES)\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel.summary()","metadata":{"execution":{"iopub.execute_input":"2025-10-09T18:00:29.305754Z","iopub.status.busy":"2025-10-09T18:00:29.305512Z","iopub.status.idle":"2025-10-09T18:00:30.463177Z","shell.execute_reply":"2025-10-09T18:00:30.462622Z","shell.execute_reply.started":"2025-10-09T18:00:29.305737Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"execution_count":null},{"id":"71010ad8","cell_type":"code","source":"\nEPOCHS = 30\n\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_accuracy',\n    patience=5,\n    restore_best_weights=True\n)\n\nhistory = model.fit(\n    train_dataset,\n    validation_data=validation_dataset,\n    epochs=EPOCHS,\n    callbacks=[early_stopping]\n)","metadata":{"execution":{"iopub.execute_input":"2025-10-09T18:00:30.465283Z","iopub.status.busy":"2025-10-09T18:00:30.464813Z","iopub.status.idle":"2025-10-09T18:13:38.704367Z","shell.execute_reply":"2025-10-09T18:13:38.703621Z","shell.execute_reply.started":"2025-10-09T18:00:30.465265Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"execution_count":null},{"id":"f0d9c015","cell_type":"code","source":"\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(len(acc))\n\nplt.figure(figsize=(14, 6))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()\n\n\ny_pred_probs = model.predict(validation_dataset)\ny_pred = np.argmax(y_pred_probs, axis=1)\ny_true = np.concatenate([y for x, y in validation_dataset], axis=0)\n\n\nprint(\"\\\\nClassification Report:\\\\n\")\nprint(classification_report(y_true, y_pred, target_names=class_names))\n\n\nconf_matrix = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n            xticklabels=class_names, yticklabels=class_names)\nplt.title('Confusion Matrix')\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2025-10-09T18:13:38.705251Z","iopub.status.busy":"2025-10-09T18:13:38.705060Z","iopub.status.idle":"2025-10-09T18:13:42.438872Z","shell.execute_reply":"2025-10-09T18:13:42.438064Z","shell.execute_reply.started":"2025-10-09T18:13:38.705236Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"execution_count":null},{"id":"28181320","cell_type":"code","source":"# --- ROC AUC Curve Visualization ---\n\ny_true_binarized = label_binarize(y_true, classes=range(NUM_CLASSES))\n\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\n\nfor i in range(NUM_CLASSES):\n    fpr[i], tpr[i], _ = roc_curve(y_true_binarized[:, i], y_pred_probs[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n\nplt.figure(figsize=(10, 8))\n\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green'])\n\nfor i, color in zip(range(NUM_CLASSES), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(class_names[i], roc_auc[i]))\n\n\nplt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier')\n\n\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve for Multi-Class')\nplt.legend(loc=\"lower right\")\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2025-10-09T18:13:42.440160Z","iopub.status.busy":"2025-10-09T18:13:42.439865Z","iopub.status.idle":"2025-10-09T18:13:42.689473Z","shell.execute_reply":"2025-10-09T18:13:42.688742Z","shell.execute_reply.started":"2025-10-09T18:13:42.440128Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"execution_count":null},{"id":"cf43e5ea","cell_type":"code","source":"\nmodel.save(\"dementia_cnn_bilstm_attention_model.h5\")\nprint(\"Model saved successfully as dementia_cnn_bilstm_attention_model.h5\")","metadata":{"execution":{"iopub.execute_input":"2025-10-09T18:13:42.691183Z","iopub.status.busy":"2025-10-09T18:13:42.690435Z","iopub.status.idle":"2025-10-09T18:13:42.883957Z","shell.execute_reply":"2025-10-09T18:13:42.883129Z","shell.execute_reply.started":"2025-10-09T18:13:42.691161Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"execution_count":null},{"id":"857ccbec","cell_type":"code","source":"# --- Grad-CAM Implementation ---\ndef compute_gradcam(model, img_array, class_idx, layer_name='last_conv'):\n    \n    grad_model = Model(inputs=model.inputs, outputs=[model.get_layer(layer_name).output, model.output])\n    \n    with tf.GradientTape() as tape:\n        conv_outputs, predictions = grad_model(img_array)\n        loss = predictions[:, class_idx]\n    \n    \n    grads = tape.gradient(loss, conv_outputs)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n    \n    \n    conv_outputs = conv_outputs[0]\n    \n    \n    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0)\n    heatmap = heatmap / tf.reduce_max(heatmap + 1e-10) \n    return heatmap.numpy()\n\ndef overlay_heatmap(heatmap, img_array, alpha=0.6, colormap=cv2.COLORMAP_INFERNO):\n   \n    if len(heatmap.shape) > 2:\n        heatmap = heatmap.squeeze()\n\n    \n    heatmap = cv2.resize(heatmap, (img_array.shape[2], img_array.shape[1]), interpolation=cv2.INTER_LINEAR)\n\n    \n    heatmap = np.maximum(heatmap, 0)\n    heatmap = heatmap / np.max(heatmap + 1e-10)\n\n   \n    heatmap[heatmap < 0.5] = 0\n\n    \n    heatmap = np.uint8(255 * heatmap)\n    heatmap = cv2.applyColorMap(heatmap, colormap)\n\n   \n    img = np.uint8(255 * img_array[0, ..., 0])\n    img_rgb = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n\n    \n    superimposed_img = cv2.addWeighted(heatmap, alpha, img_rgb, 1 - alpha, 0)\n    return superimposed_img\n\n\ndef load_and_preprocess_image(image_path, target_size=(128, 128)):\n    \n    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n    if img is None:\n        raise ValueError(f\"Could not load image from {image_path}\")\n    \n  \n    img = cv2.resize(img, target_size, interpolation=cv2.INTER_LINEAR)\n    \n   \n    img = img.astype(np.float32) / 255.0\n    \n   \n    img = np.expand_dims(img, axis=(0, -1))\n    return img\n\n#image path put here ............\nimage_path = \"/kaggle/input/augmented-alzheimer-dataset/AugmentedAlzheimerDataset/severeDementia/003c36ee-8c43-41ce-b5e5-90622644bba5.jpg\"  \n\n\nsample_img = load_and_preprocess_image(image_path)\nprint(\"Sample image shape:\", sample_img.shape)\n\n\npreds = model.predict(sample_img)\npred_class_idx = np.argmax(preds[0])\npred_class_name = class_names[pred_class_idx]\n\n\nheatmap = compute_gradcam(model, sample_img, pred_class_idx)\n\n\nsuperimposed_img = overlay_heatmap(heatmap, sample_img)\nplt.figure(figsize=(8, 4))\nplt.subplot(1, 2, 1)\nplt.title('Original Image')\nplt.imshow(sample_img[0, ..., 0], cmap='gray')\nplt.subplot(1, 2, 2)\nplt.title(f'Grad-CAM: {pred_class_name}')\nplt.imshow(superimposed_img)\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2025-10-10T08:57:45.918096Z","iopub.status.busy":"2025-10-10T08:57:45.917923Z","iopub.status.idle":"2025-10-10T08:57:46.013599Z","shell.execute_reply":"2025-10-10T08:57:46.012605Z","shell.execute_reply.started":"2025-10-10T08:57:45.918081Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"outputs":[],"execution_count":null}]}